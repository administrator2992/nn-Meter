{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use nn-Meter Benchmark Dataset\n",
    "nn-Meter collects and generates 26k CNN models. The dataset is released and an interface of `nn_meter.dataset` is provided for users to get access to the dataset. In this notebook, we showed how to use nn-Meter benchmark dataset for nn-Meter latency prediction, and, as a extension, for GNN latency prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model group: alexnets.jsonl\n",
      "Model group: densenets.jsonl\n",
      "Model group: googlenets.jsonl\n",
      "Model group: mnasnets.jsonl\n",
      "Model group: mobilenetv1s.jsonl\n",
      "Model group: mobilenetv2s.jsonl\n",
      "Model group: mobilenetv3s.jsonl\n",
      "Model group: nasbench201s.jsonl\n",
      "Model group: proxylessnass.jsonl\n",
      "Model group: resnets.jsonl\n",
      "Model group: shufflenetv2s.jsonl\n",
      "Model group: squeezenets.jsonl\n",
      "Model group: vggs.jsonl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from nn_meter.dataset import bench_dataset\n",
    "\n",
    "datasets = bench_dataset()\n",
    "for data in datasets:\n",
    "    print(f\"Model group: {os.path.basename(data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 13 groups of models in the benchmark dataset. In each groups, about 2000 model with different parameters were sampled.\n",
    "\n",
    "Dataset schema: for each model, the dataset stores its: \n",
    "- model id\n",
    "- graph in nn-meter IR graph format \n",
    "- latency numbers on four devices\n",
    "\n",
    "Here we export some information of one model to show the schema of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict keys: ['id', 'cortexA76cpu_tflite21', 'adreno640gpu_tflite21', 'adreno630gpu_tflite21', 'myriadvpu_openvino2019r2', 'graph']\n",
      "model id alexnet_1356\n",
      "cpu latency:  148.164\n",
      "adreno640gpu latency:  24.4851\n",
      "adreno630gpu latency:  31.932404999999996\n",
      "intelvpu latency:  15.486\n",
      "model graph is stored in nn-meter IR (shows only one node here): {'inbounds': ['input_im_0'], 'attr': {'name': 'conv1.conv/Conv2D', 'type': 'Conv2D', 'output_shape': [[1, 56, 56, 63]], 'attr': {'dilations': [1, 1], 'strides': [4, 4], 'data_format': 'NHWC', 'padding': 'VALID', 'kernel_shape': [7, 7], 'weight_shape': [7, 7, 3, 63], 'pads': [0, 0, 0, 0]}, 'input_shape': [[1, 224, 224, 3]]}, 'outbounds': ['conv1.relu.relu/Relu']}\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "test_data = datasets[0]\n",
    "with jsonlines.open(test_data) as data_reader:\n",
    "    True_lat = []\n",
    "    Pred_lat = []\n",
    "    for i, item in enumerate(data_reader):\n",
    "        print('dict keys:',list(item.keys()))\n",
    "        print('model id',item['id'])\n",
    "        print('cpu latency: ',item['cortexA76cpu_tflite21'])\n",
    "        print('adreno640gpu latency: ',item['adreno640gpu_tflite21'])\n",
    "        print('adreno630gpu latency: ',item['adreno630gpu_tflite21'])\n",
    "        print('intelvpu latency: ',item['myriadvpu_openvino2019r2'])\n",
    "        print('model graph is stored in nn-meter IR (shows only one node here):',\\\n",
    "            item['graph']['conv1.conv/Conv2D'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use nn-Meter predictor with benchmark dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiahang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.23.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/jiahang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator RandomForestRegressor from version 0.23.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import nn_meter\n",
    "\n",
    "predictor_name = 'adreno640gpu_tflite21' # user can change text here to test other predictors\n",
    "\n",
    "# load predictor\n",
    "predictor = nn_meter.load_latency_predictor(predictor_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT] alexnets.jsonl[0]: predict: 23.447085575244767, real: 24.4851\n",
      "[RESULT] alexnets.jsonl[1]: predict: 23.885675776357132, real: 23.9185\n",
      "[RESULT] alexnets.jsonl[2]: predict: 29.586297830632216, real: 30.3052\n",
      "[RESULT] alexnets.jsonl[3]: predict: 51.12333226388625, real: 52.089\n",
      "[RESULT] alexnets.jsonl[4]: predict: 4.937166470494071, real: 5.26442\n",
      "[RESULT] alexnets.jsonl[5]: predict: 14.996201148770355, real: 15.2265\n",
      "[RESULT] alexnets.jsonl[6]: predict: 9.262593840400983, real: 9.12046\n",
      "[RESULT] alexnets.jsonl[7]: predict: 13.912859618198581, real: 14.2242\n",
      "[RESULT] alexnets.jsonl[8]: predict: 15.02293612116675, real: 15.2457\n",
      "[RESULT] alexnets.jsonl[9]: predict: 12.443609556620192, real: 12.5989\n",
      "[RESULT] alexnets.jsonl[10]: predict: 15.971239887611217, real: 15.185\n",
      "[RESULT] alexnets.jsonl[11]: predict: 19.469347190777857, real: 20.1434\n",
      "[RESULT] alexnets.jsonl[12]: predict: 12.580476335563757, real: 14.4818\n",
      "[RESULT] alexnets.jsonl[13]: predict: 18.514081238237033, real: 19.0136\n",
      "[RESULT] alexnets.jsonl[14]: predict: 7.330729281187614, real: 7.7855\n",
      "[RESULT] alexnets.jsonl[15]: predict: 14.860185617106685, real: 15.7775\n",
      "[RESULT] alexnets.jsonl[16]: predict: 15.788781165175774, real: 16.0765\n",
      "[RESULT] alexnets.jsonl[17]: predict: 35.33131516111195, real: 35.7741\n",
      "[RESULT] alexnets.jsonl[18]: predict: 12.409197810645443, real: 12.4725\n",
      "[RESULT] alexnets.jsonl[19]: predict: 37.08473259556314, real: 36.4975\n",
      "[SUMMARY] The first 20 cases from alexnets.jsonl on adreno640gpu_tflite21: rmse: 0.6889098264185193, 5%accuracy: 0.75, 10%accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "# view latency prediction demo in one model group of the dataset \n",
    "test_data = datasets[0]\n",
    "with jsonlines.open(test_data) as data_reader:\n",
    "    True_lat = []\n",
    "    Pred_lat = []\n",
    "    for i, item in enumerate(data_reader):\n",
    "        if i >= 20: # only show the first 20 results to save space\n",
    "            break\n",
    "        graph = item[\"graph\"]\n",
    "        pred_lat = predictor.predict(graph, model_type=\"nnmeter-ir\")\n",
    "        real_lat = item[predictor_name]\n",
    "        print(f'[RESULT] {os.path.basename(test_data)}[{i}]: predict: {pred_lat}, real: {real_lat}')\n",
    "\n",
    "        if real_lat != None:\n",
    "            True_lat.append(real_lat)\n",
    "            Pred_lat.append(pred_lat)\n",
    "\n",
    "if len(True_lat) > 0:\n",
    "    rmse, rmspe, error, acc5, acc10, _ = nn_meter.latency_metrics(Pred_lat, True_lat)\n",
    "    print(\n",
    "        f'[SUMMARY] The first 20 cases from {os.path.basename(test_data)} on {predictor_name}: rmse: {rmse}, 5%accuracy: {acc5}, 10%accuracy: {acc10}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use benckmark dataset for GNN\n",
    "\n",
    "Considering the dataset is encoded in a graph format, we also provide interfaces, i.e., `GNNDataset` and `GNNDataloader`, for GNN training to predict the model latency with the bench dataset. \n",
    "\n",
    "`GNNDataset` and `GNNDataloader` in `nn_meter/dataset/gnn_dataloader.py` build the model structure of the Dataset in `.jsonl` format into GNN required Dataset and Dataloader. The output of GNNDataset includes adjacency matrix and attributes of the graph, together with latency value. The script depends on package `torch` and `dgl`.\n",
    "\n",
    "Here we provide dataset for GNN training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Training Set.\n",
      "Processing Testing Set.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Size: 20732\n",
      "Testing Dataset Size: 5173\n",
      "Attribute tensor shape: 26\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from nn_meter.dataset import gnn_dataloader\n",
    "\n",
    "target_device = \"cortexA76cpu_tflite21\"\n",
    "\n",
    "print(\"Processing Training Set.\")\n",
    "train_set = gnn_dataloader.GNNDataset(train=True, device=target_device) \n",
    "print(\"Processing Testing Set.\")\n",
    "test_set = gnn_dataloader.GNNDataset(train=False, device=target_device)\n",
    "\n",
    "train_loader = gnn_dataloader.GNNDataloader(train_set, batchsize=1 , shuffle=True)\n",
    "test_loader = gnn_dataloader.GNNDataloader(test_set, batchsize=1, shuffle=False)\n",
    "print('Train Dataset Size:', len(train_set))\n",
    "print('Testing Dataset Size:', len(test_set))\n",
    "print('Attribute tensor shape:', next(train_loader)[1].ndata['h'].size(1))\n",
    "ATTR_COUNT = next(train_loader)[1].ndata['h'].size(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we build a GNN model, which is constructed based on GraphSAGE, and maxpooling is selected as out pooling method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.module import Module\n",
    "import dgl.nn as dglnn\n",
    "from dgl.nn.pytorch.glob import MaxPooling\n",
    "\n",
    "class GNN(Module):\n",
    "    def __init__(self, \n",
    "                num_features=0, \n",
    "                num_layers=2,\n",
    "                num_hidden=32,\n",
    "                dropout_ratio=0):\n",
    "\n",
    "        super(GNN, self).__init__()\n",
    "        self.nfeat = num_features\n",
    "        self.nlayer = num_layers\n",
    "        self.nhid = num_hidden\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.gc = nn.ModuleList([dglnn.SAGEConv(self.nfeat if i==0 else self.nhid, self.nhid, 'pool') for i in range(self.nlayer)])\n",
    "        self.bn = nn.ModuleList([nn.LayerNorm(self.nhid) for i in range(self.nlayer)])\n",
    "        self.relu = nn.ModuleList([nn.ReLU() for i in range(self.nlayer)])\n",
    "        self.pooling = MaxPooling()\n",
    "        self.fc = nn.Linear(self.nhid, 1)\n",
    "        self.fc1 = nn.Linear(self.nhid, self.nhid)\n",
    "        self.dropout = nn.ModuleList([nn.Dropout(self.dropout_ratio) for i in range(self.nlayer)])\n",
    "\n",
    "    def forward_single_model(self, g, features):\n",
    "        x = self.relu[0](self.bn[0](self.gc[0](g, features)))\n",
    "        x = self.dropout[0](x)\n",
    "        for i in range(1,self.nlayer):\n",
    "            x = self.relu[i](self.bn[i](self.gc[i](g, x)))\n",
    "            x = self.dropout[i](x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        x = self.forward_single_model(g, features)\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = x\n",
    "            x = self.pooling(g, x)\n",
    "            x = self.fc1(x)\n",
    "            return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start GNN training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  0 ]:  Training accuracy within 10%:  22.486976654447233  %.\n",
      "[Epoch  1 ]:  Training accuracy within 10%:  29.471348639783905  %.\n",
      "[Epoch  2 ]:  Training accuracy within 10%:  32.60659849508007  %.\n",
      "[Epoch  3 ]:  Training accuracy within 10%:  37.830407100135055  %.\n",
      "[Epoch  4 ]:  Training accuracy within 10%:  43.32915300019294  %.\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using CUDA.\")\n",
    "# device = \"cpu\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Start Training\n",
    "model = GNN(ATTR_COUNT, 3, 400, 0.1).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=4e-4)\n",
    "EPOCHS=5\n",
    "loss_func = nn.L1Loss()\n",
    "\n",
    "lr_scheduler = CosineAnnealingLR(opt, T_max=EPOCHS)\n",
    "loss_sum = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    train_length = len(train_set)\n",
    "    tran_acc_ten = 0\n",
    "    loss_sum = 0 \n",
    "    # latency, graph, types, flops\n",
    "    for batched_l, batched_g in train_loader:\n",
    "        opt.zero_grad()\n",
    "        batched_l = batched_l.to(device).float()\n",
    "        batched_g = batched_g.to(device)\n",
    "        batched_f = batched_g.ndata['h'].float()\n",
    "        logits = model(batched_g, batched_f)\n",
    "        for i in range(len(batched_l)):\n",
    "            pred_latency = logits[i].item()\n",
    "            prec_latency = batched_l[i].item()\n",
    "            if (pred_latency >= 0.9 * prec_latency) and (pred_latency <= 1.1 * prec_latency):\n",
    "                tran_acc_ten += 1\n",
    "        # print(\"true latency: \", batched_l)\n",
    "        # print(\"Predict latency: \", logits)\n",
    "        batched_l = torch.reshape(batched_l, (-1 ,1))\n",
    "        loss = loss_func(logits, batched_l)\n",
    "        loss_sum += loss\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    lr_scheduler.step()\n",
    "    print(\"[Epoch \", epoch, \"]: \", \"Training accuracy within 10%: \", tran_acc_ten / train_length * 100, \" %.\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2602612169f43f91d25fe52816b7763616055f24dc48b1edca6c7b81a282af45"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('py36': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
